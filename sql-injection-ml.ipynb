{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2021-11-22T13:14:38.967409Z","iopub.status.busy":"2021-11-22T13:14:38.96648Z","iopub.status.idle":"2021-11-22T13:14:38.994955Z","shell.execute_reply":"2021-11-22T13:14:38.993808Z","shell.execute_reply.started":"2021-11-22T13:14:38.967308Z"},"id":"IMPVZK2F683D"},"source":["**IMPORTS**"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-16T06:16:18.164332Z","iopub.status.busy":"2023-09-16T06:16:18.163629Z","iopub.status.idle":"2023-09-16T06:16:29.199654Z","shell.execute_reply":"2023-09-16T06:16:29.198503Z","shell.execute_reply.started":"2023-09-16T06:16:18.164301Z"},"id":"TVBsdTmJ683J","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from nltk.corpus import stopwords\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.layers import (\n","    Input,\n","    Embedding,\n","    Attention,\n","    LayerNormalization,\n","    Dense,\n",")\n","from sklearn import tree\n","from tensorflow import keras\n","from tensorflow.keras import models, layers\n","import warnings\n","\n","from sklearn.metrics import (\n","    confusion_matrix,\n","    classification_report,\n","    f1_score,\n","    precision_score,\n","    recall_score,\n","    accuracy_score,\n",")\n","from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n","import seaborn as sns\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, roc_auc_score, auc\n","\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","metadata":{"id":"zq84qpPI683M"},"source":["**LOADING AND PREPROCESSING DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.202218Z","iopub.status.busy":"2023-09-16T06:16:29.201608Z","iopub.status.idle":"2023-09-16T06:16:29.291840Z","shell.execute_reply":"2023-09-16T06:16:29.290677Z","shell.execute_reply.started":"2023-09-16T06:16:29.202188Z"},"id":"pwXfL2xxEwaM","outputId":"bd7f74bc-e2c4-4dab-c2cc-271e3a0e3f74","trusted":true},"outputs":[],"source":["path = './clean_data.csv'\n","df = pd.read_csv(path, encoding='utf-8')\n","print(\"Data Shape:\", df.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.294639Z","iopub.status.busy":"2023-09-16T06:16:29.293793Z","iopub.status.idle":"2023-09-16T06:16:29.303983Z","shell.execute_reply":"2023-09-16T06:16:29.302811Z","shell.execute_reply.started":"2023-09-16T06:16:29.294572Z"},"id":"B6OuxIyx683N","outputId":"13d0213d-3e8a-444f-9c56-383a2f0fcbb8","trusted":true},"outputs":[],"source":["X = df['Sentence']\n","y = df['Label']\n","print(X.shape, y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:29.308515Z","iopub.status.busy":"2023-09-16T06:16:29.307786Z","iopub.status.idle":"2023-09-16T06:16:31.228445Z","shell.execute_reply":"2023-09-16T06:16:31.227378Z","shell.execute_reply.started":"2023-09-16T06:16:29.308478Z"},"id":"nNTZPR3jE3tX","outputId":"9f1daf8a-f316-4525-a4fb-77ea5da1385a","trusted":true},"outputs":[],"source":["import nltk\n","nltk.download('stopwords')\n","vectorizer = CountVectorizer(min_df = 2, max_df = 0.8, stop_words = stopwords.words('english'))\n","X = vectorizer.fit_transform(X.values.astype('U')).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:31.231432Z","iopub.status.busy":"2023-09-16T06:16:31.230708Z","iopub.status.idle":"2023-09-16T06:16:32.104169Z","shell.execute_reply":"2023-09-16T06:16:32.102934Z","shell.execute_reply.started":"2023-09-16T06:16:31.231393Z"},"id":"ab38XMjUE0ct","outputId":"0c6fab19-1669-4aaa-f345-4938c73eaa04","trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) #Train 80 Test 20"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.106250Z","iopub.status.busy":"2023-09-16T06:16:32.105864Z","iopub.status.idle":"2023-09-16T06:16:32.111956Z","shell.execute_reply":"2023-09-16T06:16:32.110754Z","shell.execute_reply.started":"2023-09-16T06:16:32.106214Z"},"id":"4tRntf4etCpz","trusted":true},"outputs":[],"source":["f1_dict = {}\n","precision_dict = {}\n","recall_dict = {}\n","accuracy_dict = {}\n","train_accuracy = {}\n","validation_accuracy = {}\n","test_accuracy = {}"]},{"cell_type":"markdown","metadata":{},"source":["# Scenarios"]},{"cell_type":"markdown","metadata":{},"source":["## Support function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to plot the history graphs of the training and validation curves during training\n","def plot_history(history):\n","    history_dict = history.history\n","    train_loss = history_dict['loss']    # Training loss over epochs\n","    val_loss = history_dict['val_loss']    # Validation loss over epochs\n","    epochs = range(1, len(history_dict['loss'])+1)\n","    plt.plot(epochs, train_loss,'b', label='Training error')\n","    plt.plot(epochs, val_loss,'b', color=\"orange\", label='Validation error')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","def plot_historyAcc(history):\n","    history_dict = history.history\n","    train_acc = history_dict['accuracy']    # Training loss over epochs\n","    val_acc = history_dict['val_accuracy']    # Validation loss over epochs\n","    epochs = range(1, len(history_dict['accuracy'])+1)\n","    plt.plot(epochs, train_acc,'b', label='Training accuracy')\n","    plt.plot(epochs, val_acc,'b', color=\"orange\", label='Validation accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n","\n","# Function to plot the confusion matrix\n","def plot_confusion_matrix(conf_matrix):    \n","    fig, ax = plt.subplots(figsize=(7.5, 7.5))\n","    ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n","    for i in range(conf_matrix.shape[0]):\n","        for j in range(conf_matrix.shape[1]):\n","            ax.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n","    \n","    plt.xlabel('Predicted Value', fontsize=18)\n","    plt.ylabel('Actual Value', fontsize=18)\n","    plt.title('Confusion Matrix', fontsize=18)\n","    plt.show()\n","\n","def plot_roc_auc(model, X_test, y_test):\n","    # Predict probabilities for the positive class\n","    y_pred_proba = model.predict(X_test)\n","    \n","    # Extract probabilities for the positive class (assuming binary classification)\n","    if y_pred_proba.shape[1] > 1:\n","        y_pred_proba = y_pred_proba[:, 1]\n","    \n","    # Compute ROC curve\n","    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Plot ROC curve\n","    plt.figure(figsize=(8, 6))\n","    plt.plot(fpr, tpr, label=f'{model.__class__.__name__} (AUC = {roc_auc:.2f})')\n","    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Classifier (AUC = 0.5)')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve for {model.name}')\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","def plot_report(y_test, y_pred):\n","    conf_matrix_model = confusion_matrix(y_test, y_pred)\n","    plot_confusion_matrix(conf_matrix_model)\n","    print(classification_report(y_test, y_pred, target_names=[\"Non-Intrusion\", \"Intrusion\"]))"]},{"cell_type":"markdown","metadata":{},"source":["# ML"]},{"cell_type":"markdown","metadata":{"id":"DgotjNrO683P"},"source":["**LOGISTIC REGRESSION**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.114852Z","iopub.status.busy":"2023-09-16T06:16:32.113481Z","iopub.status.idle":"2023-09-16T06:16:32.124162Z","shell.execute_reply":"2023-09-16T06:16:32.123127Z","shell.execute_reply.started":"2023-09-16T06:16:32.114816Z"},"id":"hN1rIraz683Q","outputId":"519666f4-03df-4fd3-f083-0eadb97d3a91","trusted":true},"outputs":[],"source":["# lr_clf = LogisticRegression()\n","# y_pred_lr = lr_clf.fit(X_train, y_train)\n","# y_pred = y_pred_lr.predict(X_test)\n","# print(f\"Accuracy of Logistic Regression on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of Logistic Regression on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"LogisticRegression\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"LogisticRegression\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"LogisticRegression\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['LogisticRegression'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{"id":"DrntARHO683R"},"source":["**RANDOM FOREST**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.128048Z","iopub.status.busy":"2023-09-16T06:16:32.127692Z","iopub.status.idle":"2023-09-16T06:16:32.139883Z","shell.execute_reply":"2023-09-16T06:16:32.138813Z","shell.execute_reply.started":"2023-09-16T06:16:32.128023Z"},"id":"Ad6-zNAR683S","outputId":"09aa79e3-35e0-4edb-cad0-171c04390326","trusted":true},"outputs":[],"source":["# rf_clf = RandomForestClassifier()\n","# rf_clf.fit(X_train, y_train)\n","# y_pred = rf_clf.predict(X_test)\n","# print(f\"Accuracy of Random Forest on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of Random Forest on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"RandomForest\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"RandomForest\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"RandomForest\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['RandomForest'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{"id":"I-TM5IRV683T"},"source":["**SUPPORT VECTOR MACHINES**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.142258Z","iopub.status.busy":"2023-09-16T06:16:32.141861Z","iopub.status.idle":"2023-09-16T06:16:32.151088Z","shell.execute_reply":"2023-09-16T06:16:32.149963Z","shell.execute_reply.started":"2023-09-16T06:16:32.142221Z"},"id":"BLbz8NpW683T","outputId":"ab296a24-c57e-4202-eb3e-20540673215b","trusted":true},"outputs":[],"source":["# svm_clf = SVC(gamma = 'auto')\n","# svm_clf.fit(X_train, y_train)\n","# y_pred = svm_clf.predict(X_test)\n","# print(f\"Accuracy of SVM on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of SVM on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"SVM\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"SVM\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"SVM\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['SVM'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{"id":"eBUdKeBH683U"},"source":["**NAIVE BAYES**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.156724Z","iopub.status.busy":"2023-09-16T06:16:32.156225Z","iopub.status.idle":"2023-09-16T06:16:32.162127Z","shell.execute_reply":"2023-09-16T06:16:32.161023Z","shell.execute_reply.started":"2023-09-16T06:16:32.156695Z"},"id":"U0oiBYMU683V","outputId":"aab99fe7-3c72-4692-f2fc-96cdcd6b2a1a","trusted":true},"outputs":[],"source":["# nb_clf = GaussianNB()\n","# nb_clf.fit(X_train, y_train)\n","# y_pred = nb_clf.predict(X_test)\n","# print(f\"Accuracy of Naive Bayes on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of Naive Bayes on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"NaiveBayes\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"NaiveBayes\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"NaiveBayes\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['NaiveBayes'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{"id":"7aRsJyZiGSy-"},"source":["**DECISION TREES**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.164175Z","iopub.status.busy":"2023-09-16T06:16:32.163766Z","iopub.status.idle":"2023-09-16T06:16:32.181451Z","shell.execute_reply":"2023-09-16T06:16:32.180205Z","shell.execute_reply.started":"2023-09-16T06:16:32.164140Z"},"id":"t4zC42NwGSKe","outputId":"5849f20f-7153-4746-bca0-223870cf1ab0","trusted":true},"outputs":[],"source":["# DT = tree.DecisionTreeClassifier()\n","# DT.fit(X_train, y_train)\n","# y_pred = DT.predict(X_test)\n","# print(f\"Accuracy of Naive Bayes on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of Naive Bayes on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"DecisionTree\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"DecisionTree\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"DecisionTree\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['DecisionTree'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Deep Learning"]},{"cell_type":"markdown","metadata":{"id":"Gxs5Buge683V"},"source":["**CONVOLUTIONAL NEURAL NETWORK**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.205399Z","iopub.status.busy":"2023-09-16T06:16:32.204684Z","iopub.status.idle":"2023-09-16T06:16:32.216040Z","shell.execute_reply":"2023-09-16T06:16:32.214842Z","shell.execute_reply.started":"2023-09-16T06:16:32.205356Z"},"trusted":true},"outputs":[],"source":["# X_train1 = X_train.reshape(-1, 1, 6509)\n","# X_test1 = X_test.reshape(-1, 1, 6509)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:21:34.768091Z","iopub.status.busy":"2023-09-16T06:21:34.767695Z","iopub.status.idle":"2023-09-16T06:21:34.773204Z","shell.execute_reply":"2023-09-16T06:21:34.772142Z","shell.execute_reply.started":"2023-09-16T06:21:34.768058Z"},"trusted":true},"outputs":[],"source":["# train_shape = X_train1.shape[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:16:32.218203Z","iopub.status.busy":"2023-09-16T06:16:32.217745Z","iopub.status.idle":"2023-09-16T06:17:33.910568Z","shell.execute_reply":"2023-09-16T06:17:33.909289Z","shell.execute_reply.started":"2023-09-16T06:16:32.218167Z"},"id":"ob1MU562683W","outputId":"15a61dc0-5b8e-4a9b-d4e3-5f858892be38","trusted":true},"outputs":[],"source":["# model = models.Sequential(name=\"CNN\")\n","# model.add(layers.Conv1D(32, 1, activation = 'relu', input_shape = train_shape))\n","# model.add(layers.Conv1D(32, 1, activation = 'relu'))\n","# model.add(layers.Flatten())\n","# model.add(layers.Dense(1, activation = 'sigmoid'))\n","# model.summary()\n","# model.compile(optimizer = 'adam', loss = tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","\n","# history_cnn = model.fit(X_train1, y_train, batch_size =32, epochs = 10, validation_data = (X_test1, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:17:33.913028Z","iopub.status.busy":"2023-09-16T06:17:33.912580Z","iopub.status.idle":"2023-09-16T06:17:35.383058Z","shell.execute_reply":"2023-09-16T06:17:35.381138Z","shell.execute_reply.started":"2023-09-16T06:17:33.912978Z"},"id":"rO6xSeVL683W","outputId":"ec0c71e1-10cc-42e9-ebba-310a09a2bf50","trusted":true},"outputs":[],"source":["# y_pred = model.predict(X_test1).flatten()\n","# # y_pred1 = [1 if x>-0.5 else 0 for x in y_pred]\n","# y_pred = np.round(y_pred)\n","# print(f\"Accuracy of CNN on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of CNN on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"CNN\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"CNN\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"CNN\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['CNN'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:17:35.386789Z","iopub.status.busy":"2023-09-16T06:17:35.385454Z","iopub.status.idle":"2023-09-16T06:17:35.595674Z","shell.execute_reply":"2023-09-16T06:17:35.594577Z","shell.execute_reply.started":"2023-09-16T06:17:35.386726Z"},"id":"xCC1XeEzQfrx","outputId":"f0ee23a1-837c-49e1-ffe4-2bde38951d12","trusted":true},"outputs":[],"source":["# # Plots loss over epochs cnn\n","# plot_history(history_cnn)\n","# plot_historyAcc(history_cnn)\n","# plot_roc_auc(model, X_test1, y_test)\n","# plot_report(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["**Recurrent Neural Networks (RNNs):**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:21:38.897656Z","iopub.status.busy":"2023-09-16T06:21:38.896583Z","iopub.status.idle":"2023-09-16T06:23:05.475076Z","shell.execute_reply":"2023-09-16T06:23:05.473873Z","shell.execute_reply.started":"2023-09-16T06:21:38.897613Z"},"trusted":true},"outputs":[],"source":["# # Define the RNN model\n","# model = models.Sequential(name=\"RNN\")\n","\n","# model.add(layers.SimpleRNN(units=64, activation='relu', input_shape= train_shape))\n","\n","# # Add a Dense layer for classification (adjust units and activation as needed)\n","# model.add(layers.Dense(units=1, activation='sigmoid'))\n","\n","# # Compile the model\n","# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# history_rnn = model.fit(X_train1, y_train, batch_size = 32, epochs = 10, validation_data = (X_test1, y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T06:23:05.477824Z","iopub.status.busy":"2023-09-16T06:23:05.477390Z","iopub.status.idle":"2023-09-16T06:23:06.873196Z","shell.execute_reply":"2023-09-16T06:23:06.872024Z","shell.execute_reply.started":"2023-09-16T06:23:05.477783Z"},"trusted":true},"outputs":[],"source":["# y_pred = model.predict(X_test1).flatten()\n","# # y_pred1 = [1 if x>-0.5 else 0 for x in y_pred]\n","# y_pred = np.round(y_pred)\n","# print(f\"Accuracy of RNN on test set : {accuracy_score(y_pred, y_test)}\")\n","# print(f\"F1 Score of RNN on test set : {f1_score(y_pred, y_test)}\")\n","\n","# # Updates model score to f1_dict\n","# f1_dict[\"RNN\"] = f1_score(y_pred, y_test)\n","# precision_dict[\"RNN\"] = precision_score(y_pred, y_test)\n","# recall_dict[\"RNN\"] = recall_score(y_pred, y_test)\n","# accuracy_dict['RNN'] = accuracy_score(y_pred, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_dl_model(\n","    model_name,\n","    X_train,\n","    y_train,\n","    X_test,\n","    y_test,\n","    af=\"sigmoid\",\n","    epochs=10,\n","    dense=64,\n","    learning_rate=0.01,\n","):\n","    X_train_dl = X_train.reshape(-1, 1, 6509)\n","    X_test_dl = X_test.reshape(-1, 1, 6509)\n","    train_shape = X_train_dl.shape[1:]\n","    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n","    if model_name == \"CNN\":\n","        model = models.Sequential(name=\"CNN\")\n","        model.add(layers.Conv1D(32, 1, activation=\"relu\", input_shape=train_shape))\n","        model.add(layers.Conv1D(32, 1, activation=\"relu\"))\n","        model.add(layers.Flatten())\n","        model.add(layers.Dense(1, activation=af))\n","        model.compile(\n","            optimizer=opt,\n","            loss=tf.keras.losses.BinaryCrossentropy(),\n","            metrics=[\"accuracy\"],\n","        )\n","    elif model_name == \"RNN\":\n","        model = models.Sequential(name=\"RNN\")\n","        model.add(\n","            layers.SimpleRNN(units=dense, activation=\"relu\", input_shape=train_shape)\n","        )\n","        model.add(layers.Dense(units=1, activation=af))\n","        model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","\n","    history = model.fit(\n","        X_train_dl,\n","        y_train,\n","        batch_size=32,\n","        epochs=epochs,\n","        validation_data=(X_test_dl, y_test),\n","    )\n","    y_pred = model.predict(X_test_dl).flatten()\n","    y_pred = np.round(y_pred)\n","    print(f\"Accuracy of {model_name} on test set : {accuracy_score(y_pred, y_test)}\")\n","    print(f\"F1 Score of {model_name} on test set : {f1_score(y_pred, y_test)}\")\n","\n","    # Updates model score to f1_dict\n","    f1_dict[f\"{model_name}\"] = f1_score(y_pred, y_test)\n","    precision_dict[f\"{model_name}\"] = precision_score(y_pred, y_test)\n","    recall_dict[f\"{model_name}\"] = recall_score(y_pred, y_test)\n","    accuracy_dict[f\"{model_name}\"] = accuracy_score(y_pred, y_test)\n","\n","    #! Plotting\n","    plot_history(history)\n","    plot_historyAcc(history)\n","    plot_roc_auc(model, X_test_dl, y_test)\n","    plot_report(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_ml_model(model_name, X_train, y_train, X_test, y_test):\n","    if model_name == \"LogisticRegression\":\n","        model = LogisticRegression()\n","    elif model_name == \"RandomForest\":\n","        model = RandomForestClassifier()\n","    elif model_name == \"SVM\":\n","        model = SVC(gamma=\"auto\")\n","    elif model_name == \"NaiveBayes\":\n","        model = GaussianNB()\n","    elif model_name == \"DecisionTree\":\n","        model = tree.DecisionTreeClassifier()\n","    else:\n","        print(\"Invalid model name\")\n","        return None\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    print(f\"Accuracy of {model_name} on test set : {accuracy_score(y_pred, y_test)}\")\n","    print(f\"F1 Score of {model_name} on test set : {f1_score(y_pred, y_test)}\")\n","    f1_dict[f\"{model_name}\"] = f1_score(y_pred, y_test)\n","    precision_dict[f\"{model_name}\"] = precision_score(y_pred, y_test)\n","    recall_dict[f\"{model_name}\"] = recall_score(y_pred, y_test)\n","    accuracy_dict[f\"{model_name}\"] = accuracy_score(y_pred, y_test)\n","#!Plotting\n","    # plot_roc_auc(model, X_test, y_test)\n","    # plot_report(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["list_model_ml = [\n","    \"LogisticRegression\",\n","    \"RandomForest\",\n","    \"SVM\",\n","    \"NaiveBayes\",\n","    \"DecisionTree\",\n","]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","for model in list_model_ml:\n","    train_ml_model(model, X_train, y_train, X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["list_model_dl = [\n","    \"CNN\",\n","    \"RNN\",\n","]\n","#! Chỗ này để chỉnh kịch bản 1->5\n","scenarios = 1\n","for model in list_model_dl:\n","    if scenarios == 4 or scenarios == 5:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","        if scenarios == 5:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, epochs=20\n","            )  # Chỉnh lại epochs\n","        else:\n","            train_dl_model(model, X_train, y_train, X_test, y_test)  # mặc định\n","    else:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","        if scenarios == 1:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, dense=256\n","            )  # Chỉnh lại dense\n","        elif scenarios == 2:\n","            train_dl_model(\n","                model, X_train, y_train, X_test, y_test, af=\"softmax\", epochs=20\n","            )\n","        else:\n","            train_dl_model(model, X_train, y_train, X_test, y_test)  # mặc định"]},{"cell_type":"markdown","metadata":{},"source":["# FINAL PLOT FOR MODELS PERFORMANCE "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:17:36.443224Z","iopub.status.idle":"2023-09-16T06:17:36.443737Z","shell.execute_reply":"2023-09-16T06:17:36.443487Z","shell.execute_reply.started":"2023-09-16T06:17:36.443463Z"},"id":"1KwQysSpT0wL","outputId":"8576f88b-979b-483a-fb23-241b1ecf436f","trusted":true},"outputs":[],"source":["# keys2 = f1_dict, precision_dict, recall_dict, accuracy_dict\n","# metrics = ['F1_Score', 'Precision', 'Recall', 'Accuracy']\n","# data = pd.DataFrame(keys2)\n","# data.index = metrics\n","# data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T06:17:36.445516Z","iopub.status.idle":"2023-09-16T06:17:36.446014Z","shell.execute_reply":"2023-09-16T06:17:36.445784Z","shell.execute_reply.started":"2023-09-16T06:17:36.445760Z"},"id":"V7s1MQ3nT0ss","outputId":"0261f05b-f70b-4df5-c3ff-60e30a3ff732","trusted":true},"outputs":[],"source":["# result = data.plot(kind='bar', rot=0, figsize=(15, 7));\n","# result.legend(bbox_to_anchor=(1, 1.02), loc='upper left');"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
